{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91849f03-ae86-4d1a-84eb-edb9948acf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b0e0df-a52c-4b99-a1bc-84649e8228fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 위치 지정\n",
    "keys_file_path = os.path.join('data', 'api_keys.txt')\n",
    "\n",
    "# 파일에서 API 키를 로드하는 함수\n",
    "def load_api_keys(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        keys = json.load(file)\n",
    "    return keys\n",
    "\n",
    "# API 키 사용\n",
    "api_keys = load_api_keys(keys_file_path)\n",
    "openAI_keys = api_keys['openAI_keys']\n",
    "pinecone_keys = api_keys['pinecone_keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad523cf-8d24-4f76-b6ae-83545fd43a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 6e-05,\n",
       " 'namespaces': {'': {'vector_count': 6}},\n",
       " 'total_vector_count': 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Pinecone 연결 및 index 설정\n",
    "pc = Pinecone(api_key=pinecone_keys)\n",
    "index = pc.Index('rag')\n",
    "\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c7d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    max_tokens=2048,\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09db4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Information: {retrieval}\n",
    "Question: {query}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d33a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb35699",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"차는 어느 나라에서 주로 마시지?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d913e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input = query,\n",
    "    model=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45179d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = index.query(\n",
    "    vector=response.data[0].embedding,\n",
    "    top_k=3,\n",
    "    include_values=False,\n",
    "    include_metadata=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9aed9f-4492-4db8-9b97-fb5499c7d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Citrine Wagtail is seen throughout Europe and Central Asia.', 'The Citrine Wagtail is seen throughout Europe and Central Asia.', 'Central Asia is the land where fermented milk really came into vogue.']\n"
     ]
    }
   ],
   "source": [
    "# 찾아온 벡터들의 토큰화된 metadata들 다시 이어 붙임\n",
    "assertions_list = [match['metadata']['assertion'].strip() for match in matches['matches']]\n",
    "\n",
    "print(assertions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18fd88a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 중앙 아시아에서 발효 우유가 유행했습니다."
     ]
    }
   ],
   "source": [
    "result = llm_chain.invoke({\"retrieval\": assertions_list, \"query\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85639c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
